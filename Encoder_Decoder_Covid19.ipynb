{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lsteffenel/CHPS0905/blob/main/Encoder_Decoder_Covid19.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jgpTZhZwSiv"
      },
      "source": [
        "# Des modèles avancés pour problèmes récents\n",
        "\n",
        "Nous allons utiliser le modèle encodeur-décodeur pour prédire le nombre de cas de victimes du COVID-19."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TOLhiQhfxFpD"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "def get_df_until_2021_02_01():\n",
        "    df = pd.read_csv(\n",
        "        'COVID_19_until_2021_02_01.csv',\n",
        "        date_parser = lambda d: datetime.strptime(d, '%Y-%m-%d'),\n",
        "        index_col = 'Date'\n",
        "    )\n",
        "    return df\n",
        "\n",
        "\n",
        "def get_df_complete():\n",
        "    df = pd.read_csv(\n",
        "        'COVID_19_complete.csv',\n",
        "        date_parser = lambda d: datetime.strptime(d, '%Y-%m-%d'),\n",
        "        index_col = 'Date'\n",
        "    )\n",
        "    return df\n",
        "\n",
        "def sliding_window(ts, features, target_len = 1):\n",
        "    X, Y = [], []\n",
        "    for i in range(features + target_len, len(ts) + 1):\n",
        "        X.append(ts[i - (features + target_len):i - target_len])\n",
        "        Y.append(ts[i - target_len:i])\n",
        "    return X, Y\n",
        "\n",
        "\n",
        "def get_date_index(ts, date_index):\n",
        "    count = 0\n",
        "    for i, r in ts.iteritems():\n",
        "        if date_index == datetime.strftime(i, '%Y-%m-%d'):\n",
        "            return count\n",
        "        count = count + 1\n",
        "    return -1\n",
        "\n",
        "\n",
        "def get_train_test_datasets(ts, w, target_len, train_dates, test_dates):\n",
        "    X, Y = sliding_window(ts, w, target_len)\n",
        "    train_from = get_date_index(ts, train_dates[0]) - w\n",
        "    train_to = get_date_index(ts, train_dates[1]) - w\n",
        "    test_from = get_date_index(ts, test_dates[0]) - w\n",
        "    test_to = get_date_index(ts, test_dates[1]) - w\n",
        "\n",
        "    x_train = torch.tensor(data = X[train_from:train_to]).float()\n",
        "    y_train = torch.tensor(data = Y[train_from:train_to]).float()\n",
        "\n",
        "    x_test = torch.tensor(data = X[test_from:test_to]).float()\n",
        "    y_test = torch.tensor(data = Y[test_from:test_to]).float()\n",
        "\n",
        "    return x_train, x_test, y_train, y_test\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEQkw5Ybwe87"
      },
      "source": [
        "## Encodeur-Décodeur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gwhq4aSSubd4"
      },
      "outputs": [],
      "source": [
        "import copy\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "\n",
        "\n",
        "class Encoder(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, num_layers = 1):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        self.gru = nn.GRU(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        flat = x.view(x.shape[0], x.shape[1], self.input_size)\n",
        "        out, h = self.gru(flat)\n",
        "        return out, h\n",
        "\n",
        "\n",
        "class Decoder(nn.Module):\n",
        "\n",
        "    def __init__(self, input_size, hidden_size, hidden_dl_size, output_size = 1, num_layers = 1):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "        self.num_layers = num_layers\n",
        "        self.output_size = output_size\n",
        "\n",
        "        self.gru = nn.GRU(input_size = input_size, hidden_size = hidden_size, num_layers = num_layers)\n",
        "        self.lin1 = nn.Linear(hidden_size, hidden_dl_size)\n",
        "        self.lin2 = nn.Linear(hidden_dl_size, output_size)\n",
        "\n",
        "    def forward(self, x, h):\n",
        "        out, h = self.gru(x.unsqueeze(0), h)\n",
        "        y = torch.relu(self.lin1(out.squeeze(0)))\n",
        "        y = self.lin2(y)\n",
        "        return y, h\n",
        "\n",
        "\n",
        "class EncoderDecoder(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size, hidden_dl_size, input_size = 1, output_size = 1):\n",
        "        super(EncoderDecoder, self).__init__()\n",
        "        self.input_size = input_size\n",
        "        self.hidden_size = hidden_size\n",
        "\n",
        "        self.encoder = Encoder(input_size = input_size, hidden_size = hidden_size)\n",
        "        self.decoder = Decoder(input_size = output_size, hidden_size = hidden_size,\n",
        "                               hidden_dl_size = hidden_dl_size, output_size = output_size)\n",
        "\n",
        "    def train_model(\n",
        "            self, train, target, val, val_target,\n",
        "            epochs, target_len, method = 'recursive',\n",
        "            tfr = 0.5, lr = 0.01, dynamic_tf = False\n",
        "    ):\n",
        "        losses = np.full(epochs, np.nan)\n",
        "        optimizer = optim.Adam(self.parameters(), lr = lr)\n",
        "        criterion = nn.MSELoss()\n",
        "\n",
        "        best_val_loss = 1000_000\n",
        "        best_model_params = None\n",
        "\n",
        "        for e in range(epochs):\n",
        "            predicted = torch.zeros(target_len, train.shape[1], 1)\n",
        "            optimizer.zero_grad()\n",
        "            _, enc_h = self.encoder(train)\n",
        "\n",
        "            dec_in = train[-1, :, 0].unsqueeze(1)\n",
        "            dec_h = enc_h\n",
        "\n",
        "            if method == 'recursive':\n",
        "                for t in range(target_len):\n",
        "                    dec_out, dec_h = self.decoder(dec_in, dec_h)\n",
        "                    predicted[t] = dec_out\n",
        "                    dec_in = dec_out\n",
        "\n",
        "            if method == 'teacher_forcing':\n",
        "                # use teacher forcing\n",
        "                if random.random() < tfr:\n",
        "                    for t in range(target_len):\n",
        "                        dec_out, dec_h = self.decoder(dec_in, dec_h)\n",
        "                        predicted[t] = dec_out\n",
        "                        dec_in = target[t, :].unsqueeze(1)\n",
        "                # predict recursively\n",
        "                else:\n",
        "                    for t in range(target_len):\n",
        "                        dec_out, dec_h = self.decoder(dec_in, dec_h)\n",
        "                        predicted[t] = dec_out\n",
        "                        dec_in = dec_out\n",
        "\n",
        "            if method == 'mixed_teacher_forcing':\n",
        "                # predict using mixed teacher forcing\n",
        "                for t in range(target_len):\n",
        "                    dec_out, dec_h = self.decoder(dec_in, dec_h)\n",
        "                    predicted[t] = dec_out\n",
        "                    # predict with teacher forcing\n",
        "                    if random.random() < tfr:\n",
        "                        dec_in = target[t, :].unsqueeze(1)\n",
        "                    # predict recursively\n",
        "                    else:\n",
        "                        dec_in = dec_out\n",
        "\n",
        "            loss = criterion(predicted.squeeze(2), target)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            val_predicted = self.predict(val, val_target.size(0))\n",
        "            val_loss = criterion(val_predicted.squeeze(2), val_target)\n",
        "\n",
        "            if val_loss.item() < best_val_loss:\n",
        "                best_val_loss = val_loss.item()\n",
        "                best_model_params = copy.deepcopy(self.state_dict())\n",
        "\n",
        "            losses[e] = loss.item()\n",
        "\n",
        "            if e % 10 == 0:\n",
        "                print(f'Epoch {e}/{epochs}| '\n",
        "                      f'test: {round(loss.item(), 4)}, '\n",
        "                      f'val: {round(val_loss.item(), 4)}')\n",
        "\n",
        "            # dynamic teacher forcing\n",
        "            if dynamic_tf and tfr > 0:\n",
        "                tfr = tfr - 0.02\n",
        "\n",
        "        return best_model_params, best_val_loss\n",
        "\n",
        "    def predict(self, x, target_len):\n",
        "        y = torch.zeros(target_len, x.shape[1], 1)\n",
        "\n",
        "        _, enc_h = self.encoder(x)\n",
        "        dec_in = x[-1, :, 0].unsqueeze(1)\n",
        "        dec_h = enc_h\n",
        "\n",
        "        for t in range(target_len):\n",
        "            dec_out, dec_h = self.decoder(dec_in, dec_h)\n",
        "            y[t] = dec_out\n",
        "            dec_in = dec_out\n",
        "\n",
        "        return y\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "14EHVlAeylGy"
      },
      "outputs": [],
      "source": [
        "seed = 1\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "df = get_df_until_2021_02_01()\n",
        "start_date = '2020-01-01'\n",
        "end_date = '2021-02-01'\n",
        "countries = ['Italy', 'Russia', 'Hungary', 'Austria', 'Israel', 'Poland']\n",
        "\n",
        "# size of the sliding window\n",
        "w = 120\n",
        "# length of prediction\n",
        "out = 60\n",
        "# number of training epochs\n",
        "epochs = 2_00\n",
        "\n",
        "# Initializing the model\n",
        "params = {\n",
        "    'hidden_size':    32,\n",
        "    'hidden_dl_size': 12,\n",
        "    'input_size':     3,\n",
        "    'output_size':    1,\n",
        "    'lr':             .01,\n",
        "    'tfr':            .1\n",
        "}\n",
        "\n",
        "# Hyper-parameters:\n",
        "hidden_size = params['hidden_size']\n",
        "hidden_dl_size = params['hidden_dl_size']\n",
        "lr = params['lr']\n",
        "tfr = params['tfr']\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UXXTFvIQzC0T"
      },
      "outputs": [],
      "source": [
        "import statsmodels.api as sm\n",
        "\n",
        "# Preparing Sliding-window Datasets\n",
        "X, Y = [], []\n",
        "for c in countries:\n",
        "    # diff\n",
        "    ts_df = df[df['Country'] == c]['Confirmed'].diff().dropna()\n",
        "    train = ts_df[start_date:end_date].values\n",
        "    # Normalized time series\n",
        "    train = train / max(train)\n",
        "    # Statistical pre-processing\n",
        "    _, train_hp_trend = sm.tsa.filters.hpfilter(train)\n",
        "    train_cf_cycle, _ = sm.tsa.filters.cffilter(train)\n",
        "\n",
        "    D = []\n",
        "    for i in range(len(train)):\n",
        "        D.append([train[i], train_hp_trend[i], train_cf_cycle[i]])\n",
        "\n",
        "    # input - output for country\n",
        "    X_c, Y_c = sliding_window(D, w, out)\n",
        "    X.extend(X_c)\n",
        "    Y.extend(Y_c)\n",
        "\n",
        "# Train-Validation Split\n",
        "X_train, Y_train = [], []\n",
        "X_val, Y_val = [], []\n",
        "for i in range(len(X)):\n",
        "    if random.random() > .8:\n",
        "        X_val.append(X[i])\n",
        "        Y_val.append(Y[i])\n",
        "    else:\n",
        "        X_train.append(X[i])\n",
        "        Y_train.append(Y[i])\n",
        "\n",
        "# Converting datasets to tensors\n",
        "x_train = torch.tensor(X_train).float().transpose(0, 1)\n",
        "y_train = torch.tensor(Y_train).float().transpose(0, 1)[:, :, 0]\n",
        "x_val = torch.tensor(X_val).float().transpose(0, 1)\n",
        "y_val = torch.tensor(Y_val).float().transpose(0, 1)[:, :, 0]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m4MMqNmuzm5x"
      },
      "outputs": [],
      "source": [
        "model_params = {\n",
        "    'hidden_size':    32,\n",
        "    'hidden_dl_size': 12,\n",
        "    'input_size':     3,\n",
        "    'output_size':    1\n",
        "}\n",
        "\n",
        "model = EncoderDecoder(**model_params)\n",
        "model.train()\n",
        "\n",
        "# Training and getting the results\n",
        "model_params, val = model.train_model(\n",
        "        x_train, y_train, x_val, y_val, epochs, out,\n",
        "        method = 'mixed_teacher_forcing', tfr = tfr, lr = lr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jucvy2UF1qED"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "import datetime as dt\n",
        "import statsmodels.api as sm\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.dates as mdates\n",
        "\n",
        "model.eval()\n",
        "from_date = '2020-10-04'\n",
        "to_date = '2021-04-01'\n",
        "date_fmt = '%Y-%m-%d'\n",
        "country = 'Austria'\n",
        "df = get_df_complete()\n",
        "au_ts_df = df[df['Country'] == country]['Confirmed'].diff().dropna()\n",
        "ts = au_ts_df[from_date:to_date].values\n",
        "test = ts[:120]\n",
        "max_test = max(test)\n",
        "test = test / max_test\n",
        "test_hp_cycle, test_hp_trend = sm.tsa.filters.hpfilter(test)\n",
        "test_cf_cycle, test_cf_trend = sm.tsa.filters.cffilter(test)\n",
        "X = []\n",
        "for i in range(len(test)):\n",
        "    X.append([test[i], test_hp_trend[i], test_cf_cycle[i]])\n",
        "\n",
        "x = torch.tensor([X]).float().transpose(0, 1)\n",
        "model.eval()\n",
        "predicted = model.predict(x, 60)\n",
        "\n",
        "in_seq = [e * max_test for e in x[:, -1, 0].view(-1).tolist()]\n",
        "target_seq = list(ts[120:])\n",
        "pred_seq = [e * max_test for e in predicted[:, -1, 0].view(-1).tolist()]\n",
        "x_axis = range(len(in_seq) + len(pred_seq))\n",
        "start_date = datetime.strptime(from_date, date_fmt)\n",
        "end_date = start_date + dt.timedelta(days = len(in_seq))\n",
        "prediction_date = start_date + dt.timedelta(days = len(in_seq) + len(pred_seq))\n",
        "date_list = mdates.drange(start_date, prediction_date, dt.timedelta(days = 1))\n",
        "\n",
        "plt.title(f'Prediction for next 60 days')\n",
        "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter(date_fmt))\n",
        "plt.gca().xaxis.set_major_locator(mdates.DayLocator(interval = 35))\n",
        "plt.plot(date_list[:], in_seq + target_seq, color = 'blue')\n",
        "plt.plot(date_list[len(in_seq):],\n",
        "         pred_seq,\n",
        "         label = 'Model prediction',\n",
        "         color = 'orange',\n",
        "         linewidth = 3)\n",
        "plt.vlines(end_date, 0, max_test, color = 'grey')\n",
        "plt.legend(loc = \"upper right\")\n",
        "plt.gcf().autofmt_xdate()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from typing import OrderedDict\n",
        "\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils import weight_norm\n",
        "\n",
        "\n",
        "class Crop(nn.Module):\n",
        "\n",
        "    def __init__(self, crop_size):\n",
        "        super(Crop, self).__init__()\n",
        "        self.crop_size = crop_size\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x[:, :, :-self.crop_size].contiguous()\n",
        "\n",
        "\n",
        "class TemporalCasualLayer(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 n_inputs,\n",
        "                 n_outputs,\n",
        "                 kernel_size,\n",
        "                 stride,\n",
        "                 dilation,\n",
        "                 dropout = 0.2,\n",
        "                 act = 'relu',\n",
        "                 slices = 2,\n",
        "                 use_bias = True\n",
        "                 ):\n",
        "        super(TemporalCasualLayer, self).__init__()\n",
        "        padding = (kernel_size - 1) * dilation\n",
        "        conv_params = {\n",
        "            'kernel_size': kernel_size,\n",
        "            'stride':      stride,\n",
        "            'padding':     padding,\n",
        "            'dilation':    dilation\n",
        "        }\n",
        "        activations = {\n",
        "            'relu': nn.ReLU(),\n",
        "            'tanh': nn.Tanh()\n",
        "        }\n",
        "\n",
        "        self.use_bias = use_bias\n",
        "\n",
        "        layers = OrderedDict()\n",
        "        for s in range(1, slices + 1):\n",
        "            if s == 1:\n",
        "                layers[f'conv{s}'] = weight_norm(nn.Conv1d(n_inputs, n_outputs, **conv_params))\n",
        "            else:\n",
        "                layers[f'conv{s}'] = weight_norm(nn.Conv1d(n_outputs, n_outputs, **conv_params))\n",
        "            layers[f'crop{s}'] = Crop(padding)\n",
        "            layers[f'act{s}'] = activations[act]\n",
        "            layers[f'dropout{s}'] = nn.Dropout(dropout)\n",
        "\n",
        "        self.net = nn.Sequential(layers)\n",
        "\n",
        "        if n_inputs != n_outputs and use_bias:\n",
        "            self.bias = nn.Conv1d(n_inputs, n_outputs, 1)\n",
        "        else:\n",
        "            self.bias = None\n",
        "\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.net(x)\n",
        "        if self.use_bias:\n",
        "            b = x if self.bias is None else self.bias(x)\n",
        "            return self.relu(y + b)\n",
        "        else:\n",
        "            return self.relu(y)\n",
        "\n",
        "\n",
        "class TemporalConvolutionNetwork(nn.Module):\n",
        "\n",
        "    def __init__(self,\n",
        "                 num_inputs,\n",
        "                 num_channels,\n",
        "                 kernel_size = 2,\n",
        "                 dropout = 0.2,\n",
        "                 slices = 2,\n",
        "                 act = 'relu',\n",
        "                 use_bias = True\n",
        "                 ):\n",
        "        super(TemporalConvolutionNetwork, self).__init__()\n",
        "        layers = []\n",
        "        num_levels = len(num_channels)\n",
        "\n",
        "        tcl_param = {\n",
        "            'kernel_size': kernel_size,\n",
        "            'stride':      1,\n",
        "            'dropout':     dropout,\n",
        "            'slices':      slices,\n",
        "            'act':         act,\n",
        "            'use_bias':    use_bias\n",
        "        }\n",
        "\n",
        "        for i in range(num_levels):\n",
        "            dilation = 2**i\n",
        "            in_ch = num_inputs if i == 0 else num_channels[i - 1]\n",
        "            out_ch = num_channels[i]\n",
        "            tcl_param['dilation'] = dilation\n",
        "            tcl = TemporalCasualLayer(in_ch, out_ch, **tcl_param)\n",
        "            layers.append(tcl)\n",
        "\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "\n",
        "class TcnClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, **params):\n",
        "        super(TcnClassifier, self).__init__()\n",
        "        self.num_channels = params['num_channels']\n",
        "        self.num_classes = params.pop('num_classes')\n",
        "\n",
        "        self.tcn = TemporalConvolutionNetwork(**params)\n",
        "        self.linear = nn.Linear(self.num_channels[-1], self.num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.tcn(x)\n",
        "        x = self.linear(x[:, :, -1])\n",
        "        y = torch.log_softmax(x, dim = 1)\n",
        "        return y\n"
      ],
      "metadata": {
        "id": "1aFZS-7YChIa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Challenge\n",
        "\n",
        "l'entraînement a été fait avec des pays de l'Europe, et testé avec l'Autriche.\n",
        "\n",
        "Est-ce que ce modèle présente une bonne performance pour la France ? Et les Etats Unis ? Et l'Argentine ?\n",
        "\n",
        "En fonction de vos observations, créer des modèles par continent.\n"
      ],
      "metadata": {
        "id": "CFfJBn58Eirw"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Fst6nlBmELDY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN61vBZiIIhakz/He/CpCqh",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}